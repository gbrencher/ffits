{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595f6eea-33dc-438f-9b12-254915ef2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal, gdal_array\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from glob import glob\n",
    "import scipy.signal\n",
    "from mintpy.utils import readfile, writefile, utils as ut\n",
    "from mintpy.cli import view, tsview, plot_network, plot_transection\n",
    "from mintpy.view import prep_slice, plot_slice\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b3540b-8cb9-47c9-8b04-e618f5a57cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop geometry files\n",
    "def crop_isce_file(input_path, output_path):\n",
    "\n",
    "    input_ds = gdal.Open(input_path, gdal.GA_ReadOnly)\n",
    "    input = input_ds.GetRasterBand(1).ReadAsArray()\n",
    "    \n",
    "    input_crop = input[3250:4750, 2600:4100]\n",
    "    \n",
    "    # save cropped interferogram\n",
    "    input_crop = np.nan_to_num(input_crop, nan=0)\n",
    "    driver_format = \"ISCE\"    # Specify the GDAL format for the output (GeoTIFF in this example)\n",
    "    rows, cols = input_crop.shape    # Get the number of rows and columns from the NumPy array\n",
    "    data_type = gdal_array.NumericTypeCodeToGDALTypeCode(input_crop.dtype)  # Convert NumPy data type to GDAL data type\n",
    "    driver = gdal.GetDriverByName(driver_format)\n",
    "    output_ds = driver.Create(output_path, cols, rows, 1, data_type)\n",
    "    band = output_ds.GetRasterBand(1)  \n",
    "    band.WriteArray(input_crop)\n",
    "    output_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac39b8c3-9d01-4e02-8b3f-18d7e5e36676",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/mnt/Backups/gbrench/repos/fusits/nbs/imja/agu_push/AT12/work'\n",
    "crop_isce_file(f'{work_dir}/merged/geom_reference/hgt.rdr', f'{work_dir}/merged/geom_reference/hgt_aoi.rdr')\n",
    "crop_isce_file(f'{work_dir}/merged/geom_reference/incLocal.rdr', f'{work_dir}/merged/geom_reference/incLocal_aoi.rdr')\n",
    "crop_isce_file(f'{work_dir}/merged/geom_reference/lat.rdr', f'{work_dir}/merged/geom_reference/lat_aoi.rdr')\n",
    "crop_isce_file(f'{work_dir}/merged/geom_reference/lon.rdr', f'{work_dir}/merged/geom_reference/lon_aoi.rdr')\n",
    "crop_isce_file(f'{work_dir}/merged/geom_reference/los.rdr', f'{work_dir}/merged/geom_reference/los_aoi.rdr')\n",
    "crop_isce_file(f'{work_dir}/merged/geom_reference/shadowMask.rdr', f'{work_dir}/merged/geom_reference/shadowMask_aoi.rdr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa46b1-8c8c-45c6-9e6e-3d4e67bc7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to MintPy config file\n",
    "def write_config_file(out_file, CONFIG_TXT, mode='a'): \n",
    "    \"\"\"Write configuration files for MintPy to process products\"\"\"\n",
    "    if not os.path.isfile(out_file) or mode == 'w':\n",
    "        with open(out_file, \"w\") as fid:\n",
    "            fid.write(CONFIG_TXT)\n",
    "        print('write configuration to file: {}'.format(out_file))\n",
    "    else:\n",
    "        with open(out_file, \"a\") as fid:\n",
    "            fid.write(\"\\n\" + CONFIG_TXT)\n",
    "        print('add the following to file: \\n{}'.format(CONFIG_TXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef62a2-4308-4af9-9cc4-4e1e9e78dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_TXT = f'''\n",
    "# vim: set filetype=cfg:\n",
    "##------------------------ smallbaselineApp.cfg ------------------------##\n",
    "########## computing resource configuration\n",
    "mintpy.compute.maxMemory = 40, auto for 4, max memory to allocate in GB\n",
    "## parallel processing with dask\n",
    "## currently apply to steps: invert_network, correct_topography\n",
    "## cluster   = none to turn off the parallel computing\n",
    "## numWorker = all  to use all of locally available cores (for cluster = local only)\n",
    "## numWorker = 80%  to use 80% of locally available cores (for cluster = local only)\n",
    "## config    = none to rollback to the default name (same as the cluster type; for cluster != local)\n",
    "mintpy.compute.cluster   = local #[local / slurm / pbs / lsf / none], auto for none, cluster type\n",
    "mintpy.compute.numWorker = 4 #[int > 1 / all / num%], auto for 4 (local) or 40 (slurm / pbs / lsf), num of workers\n",
    "mintpy.compute.config    = auto #[none / slurm / pbs / lsf ], auto for none (same as cluster), config name\n",
    "\n",
    "\n",
    "########## 1. load_data\n",
    "##---------add attributes manually\n",
    "## MintPy requires attributes listed at: https://mintpy.readthedocs.io/en/latest/api/attributes/\n",
    "## Missing attributes can be added below manually (uncomment #), e.g.\n",
    "# ORBIT_DIRECTION = ascending\n",
    "# PLATFORM = Sen\n",
    "# ...\n",
    "## a. autoPath - automatic path pattern defined in mintpy.defaults.auto_path.AUTO_PATH_*\n",
    "## b. load_data.py -H to check more details and example inputs.\n",
    "## c. compression to save disk usage for ifgramStack.h5 file:\n",
    "## no   - save   0% disk usage, fast [default]\n",
    "## lzf  - save ~57% disk usage, relative slow\n",
    "## gzip - save ~62% disk usage, very slow [not recommend]\n",
    "mintpy.load.processor       = isce  #[isce, aria, hyp3, gmtsar, snap, gamma, roipac, nisar], auto for isce\n",
    "mintpy.load.autoPath        = auto  #[yes / no], auto for no, use pre-defined auto path\n",
    "mintpy.load.updateMode      = auto  #[yes / no], auto for yes, skip re-loading if HDF5 files are complete\n",
    "mintpy.load.compression     = auto  #[gzip / lzf / no], auto for no.\n",
    "##---------for ISCE only:\n",
    "mintpy.load.metaFile        = ./AT12/work  #[path of common metadata file for the stack], i.e.: ./reference/IW1.xml, ./referenceShelve/data.dat\n",
    "mintpy.load.baselineDir     = auto  #[path of the baseline dir], i.e.: ./baselines\n",
    "##---------interferogram stack:\n",
    "mintpy.load.unwFile         = auto  #[path pattern of unwrapped interferogram files]\n",
    "mintpy.load.corFile         = auto  #[path pattern of spatial coherence       files]\n",
    "mintpy.load.connCompFile    = auto  #[path pattern of connected components    files], optional but recommended\n",
    "mintpy.load.intFile         = auto  #[path pattern of wrapped interferogram   files], optional\n",
    "mintpy.load.magFile         = auto  #[path pattern of interferogram magnitude files], optional\n",
    "##---------ionosphere stack (optional):\n",
    "mintpy.load.ionUnwFile      = auto  #[path pattern of unwrapped interferogram files]\n",
    "mintpy.load.ionCorFile      = auto  #[path pattern of spatial coherence       files]\n",
    "mintpy.load.ionConnCompFile = auto  #[path pattern of connected components    files], optional but recommended\n",
    "##---------offset stack (optional):\n",
    "mintpy.load.azOffFile       = auto  #[path pattern of azimuth offset file]\n",
    "mintpy.load.rgOffFile       = auto  #[path pattern of range   offset file]\n",
    "mintpy.load.azOffStdFile    = auto  #[path pattern of azimuth offset variance file], optional but recommended\n",
    "mintpy.load.rgOffStdFile    = auto  #[path pattern of range   offset variance file], optional but recommended\n",
    "mintpy.load.offSnrFile      = auto  #[path pattern of offset signal-to-noise ratio file], optional\n",
    "##---------geometry:\n",
    "mintpy.load.demFile         = auto  #[path of DEM file]\n",
    "mintpy.load.lookupYFile     = auto  #[path of latitude /row   /y coordinate file], not required for geocoded data\n",
    "mintpy.load.lookupXFile     = auto  #[path of longitude/column/x coordinate file], not required for geocoded data\n",
    "mintpy.load.incAngleFile    = auto  #[path of incidence angle file], optional but recommended\n",
    "mintpy.load.azAngleFile     = auto  #[path of azimuth   angle file], optional\n",
    "mintpy.load.shadowMaskFile  = auto  #[path of shadow mask file], optional but recommended\n",
    "mintpy.load.waterMaskFile   = auto  #[path of water  mask file], optional but recommended\n",
    "mintpy.load.bperpFile       = auto  #[path pattern of 2D perpendicular baseline file], optional\n",
    "##---------subset (optional):\n",
    "## if both yx and lalo are specified, use lalo option unless a) no lookup file AND b) dataset is in radar coord\n",
    "mintpy.subset.yx            = auto    #[y0:y1,x0:x1 / no], auto for no\n",
    "mintpy.subset.lalo          = auto    #[S:N,W:E / no], auto for no\n",
    "##---------multilook (optional):\n",
    "## multilook while loading data with the specified method, to reduce dataset size\n",
    "## method - nearest, mean and median methods are applicable to interferogram/ionosphere/offset stack(s), except for:\n",
    "##   connected components and all geometry datasets, for which nearest is hardwired.\n",
    "## Use mean / median method with caution! It could smoothen the noise for a better SNR, but it could also smoothen the\n",
    "##   unwrapping errors, breaking the integer 2pi relationship, which is used in the unwrapping error correction.\n",
    "##   If you really want to increase the SNR, consider re-generate your stack of interferograms with more looks instead.\n",
    "mintpy.multilook.method     = auto    #[nearest, mean, median], auto for nearest - lines/rows skipping approach\n",
    "mintpy.multilook.ystep      = auto    #[int >= 1], auto for 1 - no multilooking\n",
    "mintpy.multilook.xstep      = auto    #[int >= 1], auto for 1 - no multilooking\n",
    "\n",
    "\n",
    "########## 2. modify_network\n",
    "## 1) Network modification based on temporal/perpendicular baselines, date, num of connections etc.\n",
    "mintpy.network.tempBaseMax     = auto  #[1-inf, no], auto for no, max temporal baseline in days\n",
    "mintpy.network.perpBaseMax     = auto  #[1-inf, no], auto for no, max perpendicular spatial baseline in meter\n",
    "mintpy.network.connNumMax      = auto  #[1-inf, no], auto for no, max number of neighbors for each acquisition\n",
    "mintpy.network.startDate       = auto  #[20090101 / no], auto for no\n",
    "mintpy.network.endDate         = auto  #[20110101 / no], auto for no\n",
    "mintpy.network.excludeDate     = auto  #[20080520,20090817 / no], auto for no\n",
    "mintpy.network.excludeIfgIndex = auto  #[1:5,25 / no], auto for no, list of ifg index (start from 0)\n",
    "mintpy.network.referenceFile   = auto  #[date12_list.txt / ifgramStack.h5 / no], auto for no\n",
    "\n",
    "## 2) Data-driven network modification\n",
    "## a - Coherence-based network modification = (threshold + MST) by default\n",
    "## reference: Yunjun et al. (2019, section 4.2 and 5.3.1); Chaussard et al. (2015, GRL)\n",
    "## It calculates a average coherence for each interferogram using spatial coherence based on input mask (with AOI)\n",
    "## Then it finds a minimum spanning tree (MST) network with inverse of average coherence as weight (keepMinSpanTree)\n",
    "## Next it excludes interferograms if a) the average coherence < minCoherence AND b) not in the MST network.\n",
    "mintpy.network.coherenceBased  = auto  #[yes / no], auto for no, exclude interferograms with coherence < minCoherence\n",
    "mintpy.network.minCoherence    = auto  #[0.0-1.0], auto for 0.7\n",
    "\n",
    "## b - Effective Coherence Ratio network modification = (threshold + MST) by default\n",
    "## reference: Kang et al. (2021, RSE)\n",
    "## It calculates the area ratio of each interferogram that is above a spatial coherence threshold.\n",
    "## This threshold is defined as the spatial coherence of the interferograms within the input mask.\n",
    "## It then finds a minimum spanning tree (MST) network with inverse of the area ratio as weight (keepMinSpanTree)\n",
    "## Next it excludes interferograms if a) the area ratio < minAreaRatio AND b) not in the MST network.\n",
    "mintpy.network.areaRatioBased  = auto  #[yes / no], auto for no, exclude interferograms with area ratio < minAreaRatio\n",
    "mintpy.network.minAreaRatio    = auto  #[0.0-1.0], auto for 0.75\n",
    "\n",
    "## Additional common parameters for the 2) data-driven network modification\n",
    "mintpy.network.keepMinSpanTree = auto  #[yes / no], auto for yes, keep interferograms in Min Span Tree network\n",
    "mintpy.network.maskFile        = auto  #[file name, no], auto for waterMask.h5 or no [if no waterMask.h5 found]\n",
    "mintpy.network.aoiYX           = auto  #[y0:y1,x0:x1 / no], auto for no, area of interest for coherence calculation\n",
    "mintpy.network.aoiLALO         = auto  #[S:N,W:E / no], auto for no - use the whole area\n",
    "\n",
    "\n",
    "########## 3. reference_point\n",
    "## Reference all interferograms to one common point in space\n",
    "## auto - randomly select a pixel with coherence > minCoherence\n",
    "## however, manually specify using prior knowledge of the study area is highly recommended\n",
    "##   with the following guideline (section 4.3 in Yunjun et al., 2019):\n",
    "## 1) located in a coherence area, to minimize the decorrelation effect.\n",
    "## 2) not affected by strong atmospheric turbulence, i.e. ionospheric streaks\n",
    "## 3) close to and with similar elevation as the AOI, to minimize the impact of spatially correlated atmospheric delay\n",
    "mintpy.reference.yx            = auto   #[257,151 / auto]\n",
    "mintpy.reference.lalo          = auto   #[31.8,130.8 / auto]\n",
    "mintpy.reference.maskFile      = auto   #[filename / no], auto for maskConnComp.h5\n",
    "mintpy.reference.coherenceFile = auto   #[filename], auto for avgSpatialCoh.h5\n",
    "mintpy.reference.minCoherence  = auto   #[0.0-1.0], auto for 0.85, minimum coherence for auto method\n",
    "\n",
    "\n",
    "########## quick_overview\n",
    "## A quick assessment of:\n",
    "## 1) possible groud deformation\n",
    "##    using the velocity from the traditional interferogram stacking\n",
    "##    reference: Zebker et al. (1997, JGR)\n",
    "## 2) distribution of phase unwrapping error\n",
    "##    from the number of interferogram triplets with non-zero integer ambiguity of closue phase\n",
    "##    reference: T_int in Yunjun et al. (2019, CAGEO). Related to section 3.2, equation (8-9) and Fig. 3d-e.\n",
    "\n",
    "\n",
    "########## 4. correct_unwrap_error (optional)\n",
    "## connected components (mintpy.load.connCompFile) are required for this step.\n",
    "## SNAPHU (Chem & Zebker,2001) is currently the only unwrapper that provides connected components as far as we know.\n",
    "## reference: Yunjun et al. (2019, section 3)\n",
    "## supported methods:\n",
    "## a. phase_closure          - suitable for highly redundant network\n",
    "## b. bridging               - suitable for regions separated by narrow decorrelated features, e.g. rivers, narrow water bodies\n",
    "## c. bridging+phase_closure - recommended when there is a small percentage of errors left after bridging\n",
    "mintpy.unwrapError.method          = auto  #[bridging / phase_closure / bridging+phase_closure / no], auto for no\n",
    "mintpy.unwrapError.waterMaskFile   = auto  #[waterMask.h5 / no], auto for waterMask.h5 or no [if not found]\n",
    "mintpy.unwrapError.connCompMinArea = auto  #[1-inf], auto for 2.5e3, discard regions smaller than the min size in pixels\n",
    "\n",
    "## phase_closure options:\n",
    "## numSample - a region-based strategy is implemented to speedup L1-norm regularized least squares inversion.\n",
    "##     Instead of inverting every pixel for the integer ambiguity, a common connected component mask is generated,\n",
    "##     for each common conn. comp., numSample pixels are radomly selected for inversion, and the median value of the results\n",
    "##     are used for all pixels within this common conn. comp.\n",
    "mintpy.unwrapError.numSample       = auto  #[int>1], auto for 100, number of samples to invert for common conn. comp.\n",
    "\n",
    "## bridging options:\n",
    "## ramp - a phase ramp could be estimated based on the largest reliable region, removed from the entire interferogram\n",
    "##     before estimating the phase difference between reliable regions and added back after the correction.\n",
    "## bridgePtsRadius - half size of the window used to calculate the median value of phase difference\n",
    "mintpy.unwrapError.ramp            = auto  #[linear / quadratic], auto for no; recommend linear for L-band data\n",
    "mintpy.unwrapError.bridgePtsRadius = auto  #[1-inf], auto for 50, half size of the window around end points\n",
    "\n",
    "\n",
    "########## 5. invert_network\n",
    "## Invert network of interferograms into time-series using weighted least square (WLS) estimator.\n",
    "## weighting options for least square inversion [fast option available but not best]:\n",
    "## a. var - use inverse of covariance as weight (Tough et al., 1995; Guarnieri & Tebaldini, 2008) [recommended]\n",
    "## b. fim - use Fisher Information Matrix as weight (Seymour & Cumming, 1994; Samiei-Esfahany et al., 2016).\n",
    "## c. coh - use coherence as weight (Perissin & Wang, 2012)\n",
    "## d. no  - uniform weight (Berardino et al., 2002) [fast]\n",
    "## SBAS (Berardino et al., 2002) = minNormVelocity (yes) + weightFunc (no)\n",
    "mintpy.networkInversion.weightFunc      = auto #[var / fim / coh / no], auto for var\n",
    "mintpy.networkInversion.waterMaskFile   = auto #[filename / no], auto for waterMask.h5 or no [if not found]\n",
    "mintpy.networkInversion.minNormVelocity = auto #[yes / no], auto for yes, min-norm deformation velocity / phase\n",
    "\n",
    "## mask options for unwrapPhase of each interferogram before inversion (recommend if weightFunct=no):\n",
    "## a. coherence              - mask out pixels with spatial coherence < maskThreshold\n",
    "## b. connectComponent       - mask out pixels with False/0 value\n",
    "## c. no                     - no masking [recommended].\n",
    "## d. range/azimuthOffsetStd - mask out pixels with offset std. dev. > maskThreshold [for offset]\n",
    "mintpy.networkInversion.maskDataset   = auto #[coherence / connectComponent / rangeOffsetStd / azimuthOffsetStd / no], auto for no\n",
    "mintpy.networkInversion.maskThreshold = auto #[0-inf], auto for 0.4\n",
    "mintpy.networkInversion.minRedundancy = auto #[1-inf], auto for 1.0, min num_ifgram for every SAR acquisition\n",
    "\n",
    "## Temporal coherence is calculated and used to generate the mask as the reliability measure\n",
    "## reference: Pepe & Lanari (2006, IEEE-TGRS)\n",
    "mintpy.networkInversion.minTempCoh  = auto #[0.0-1.0], auto for 0.7, min temporal coherence for mask\n",
    "mintpy.networkInversion.minNumPixel = auto #[int > 1], auto for 100, min number of pixels in mask above\n",
    "mintpy.networkInversion.shadowMask  = auto #[yes / no], auto for yes [if shadowMask is in geometry file] or no.\n",
    "\n",
    "\n",
    "########## correct_LOD\n",
    "## Local Oscillator Drift (LOD) correction (for Envisat only)\n",
    "## reference: Marinkovic and Larsen (2013, Proc. LPS)\n",
    "## automatically applied to Envisat data (identified via PLATFORM attribute)\n",
    "## and skipped for all the other satellites.\n",
    "\n",
    "\n",
    "########## correct_SET\n",
    "## Solid Earth tides (SET) correction [need to install insarlab/PySolid]\n",
    "## reference: Milbert (2018); Yunjun et al. (2022, IEEE-TGRS)\n",
    "mintpy.solidEarthTides = auto #[yes / no], auto for no\n",
    "\n",
    "\n",
    "########## 6. correct_troposphere (optional but recommended)\n",
    "## correct tropospheric delay using the following methods:\n",
    "## a. height_correlation - correct stratified tropospheric delay (Doin et al., 2009, J Applied Geop)\n",
    "## b. pyaps - use Global Atmospheric Models (GAMs) data (Jolivet et al., 2011; 2014)\n",
    "##      ERA5  - ERA5    from ECMWF [need to install PyAPS from GitHub; recommended and turn ON by default]\n",
    "##      MERRA - MERRA-2 from NASA  [need to install PyAPS from Caltech/EarthDef]\n",
    "##      NARR  - NARR    from NOAA  [need to install PyAPS from Caltech/EarthDef; recommended for N America]\n",
    "## c. gacos - use GACOS with the iterative tropospheric decomposition model (Yu et al., 2018, JGR)\n",
    "##      need to manually download GACOS products at http://www.gacos.net for all acquisitions before running this step\n",
    "mintpy.troposphericDelay.method = auto  #[pyaps / height_correlation / gacos / no], auto for pyaps\n",
    "\n",
    "## Notes for pyaps:\n",
    "## a. GAM data latency: with the most recent SAR data, there will be GAM data missing, the correction\n",
    "##    will be applied to dates with GAM data available and skipped for the others.\n",
    "## b. WEATHER_DIR: if you define an environment variable named WEATHER_DIR to contain the path to a\n",
    "##    directory, then MintPy applications will download the GAM files into the indicated directory.\n",
    "##    MintPy application will look for the GAM files in the directory before downloading a new one to\n",
    "##    prevent downloading multiple copies if you work with different dataset that cover the same date/time.\n",
    "mintpy.troposphericDelay.weatherModel = auto  #[ERA5 / MERRA / NARR], auto for ERA5\n",
    "mintpy.troposphericDelay.weatherDir   = auto  #[path2directory], auto for WEATHER_DIR or \"./\"\n",
    "\n",
    "## Notes for height_correlation:\n",
    "## Extra multilooking is applied to estimate the empirical phase/elevation ratio ONLY.\n",
    "## For an dataset with 5 by 15 looks, looks=8 will generate phase with (5*8) by (15*8) looks\n",
    "## to estimate the empirical parameter; then apply the correction to original phase (with 5 by 15 looks),\n",
    "## if the phase/elevation correlation is larger than minCorrelation.\n",
    "mintpy.troposphericDelay.polyOrder      = auto  #[1 / 2 / 3], auto for 1\n",
    "mintpy.troposphericDelay.looks          = auto  #[1-inf], auto for 8, extra multilooking num\n",
    "mintpy.troposphericDelay.minCorrelation = auto  #[0.0-1.0], auto for 0\n",
    "\n",
    "## Notes for gacos:\n",
    "## Set the path below to directory that contains the downloaded *.ztd* files\n",
    "mintpy.troposphericDelay.gacosDir = auto # [path2directory], auto for \"./GACOS\"\n",
    "\n",
    "\n",
    "########## 7. deramp (optional)\n",
    "## Estimate and remove a phase ramp for each acquisition based on the reliable pixels.\n",
    "## Recommended for localized deformation signals, i.e. volcanic deformation, landslide and land subsidence, etc.\n",
    "## NOT recommended for long spatial wavelength deformation signals, i.e. co-, post- and inter-seimic deformation.\n",
    "mintpy.deramp          = auto  #[no / linear / quadratic], auto for no - no ramp will be removed\n",
    "mintpy.deramp.maskFile = auto  #[filename / no], auto for maskTempCoh.h5, mask file for ramp estimation\n",
    "\n",
    "\n",
    "########## 8. correct_topography (optional but recommended)\n",
    "## Topographic residual (DEM error) correction\n",
    "## reference: Fattahi and Amelung (2013, IEEE-TGRS)\n",
    "## stepFuncDate      - specify stepFuncDate option if you know there are sudden displacement jump in your area,\n",
    "##                     e.g. volcanic eruption, or earthquake\n",
    "## excludeDate       - dates excluded for the error estimation\n",
    "## pixelwiseGeometry - use pixel-wise geometry (incidence angle & slant range distance)\n",
    "##                     yes - use pixel-wise geometry if they are available [slow; used by default]\n",
    "##                     no  - use the mean   geometry [fast]\n",
    "mintpy.topographicResidual                   = auto  #[yes / no], auto for yes\n",
    "mintpy.topographicResidual.polyOrder         = auto  #[1-inf], auto for 2, poly order of temporal deformation model\n",
    "mintpy.topographicResidual.phaseVelocity     = auto  #[yes / no], auto for no - use phase velocity for minimization\n",
    "mintpy.topographicResidual.stepFuncDate      = auto  #[20080529,20190704T1733 / no], auto for no, date of step jump\n",
    "mintpy.topographicResidual.excludeDate       = auto  #[20070321 / txtFile / no], auto for exclude_date.txt\n",
    "mintpy.topographicResidual.pixelwiseGeometry = auto  #[yes / no], auto for yes, use pixel-wise geometry info\n",
    "\n",
    "\n",
    "########## 9.1 residual_RMS (root mean squares for noise evaluation)\n",
    "## Calculate the Root Mean Square (RMS) of residual phase time-series for each acquisition\n",
    "## reference: Yunjun et al. (2019, section 4.9 and 5.4)\n",
    "## To get rid of long spatial wavelength component, a ramp is removed for each acquisition\n",
    "## Set optimal reference date to date with min RMS\n",
    "## Set exclude dates (outliers) to dates with RMS > cutoff * median RMS (Median Absolute Deviation)\n",
    "mintpy.residualRMS.maskFile = auto  #[file name / no], auto for maskTempCoh.h5, mask for ramp estimation\n",
    "mintpy.residualRMS.deramp   = auto  #[quadratic / linear / no], auto for quadratic\n",
    "mintpy.residualRMS.cutoff   = auto  #[0.0-inf], auto for 3\n",
    "\n",
    "########## 9.2 reference_date\n",
    "## Reference all time-series to one date in time\n",
    "## reference: Yunjun et al. (2019, section 4.9)\n",
    "## no     - do not change the default reference date (1st date)\n",
    "mintpy.reference.date = auto   #[reference_date.txt / 20090214 / no], auto for reference_date.txt\n",
    "\n",
    "\n",
    "########## 10. velocity\n",
    "## Estimate a suite of time functions [linear velocity by default]\n",
    "## from final displacement file (and from tropospheric delay file if exists)\n",
    "mintpy.timeFunc.startDate   = auto   #[20070101 / no], auto for no\n",
    "mintpy.timeFunc.endDate     = auto   #[20101230 / no], auto for no\n",
    "mintpy.timeFunc.excludeDate = auto   #[exclude_date.txt / 20080520,20090817 / no], auto for exclude_date.txt\n",
    "\n",
    "## Fit a suite of time functions\n",
    "## reference: Hetland et al. (2012, JGR) equation (2-9)\n",
    "## polynomial function    is  defined by its degree in integer. 1 for linear, 2 for quadratic, etc.\n",
    "## periodic   function(s) are defined by a list of periods in decimal years. 1 for annual, 0.5 for semi-annual, etc.\n",
    "## step       function(s) are defined by a list of onset times in str in YYYYMMDD(THHMM) format\n",
    "## exp & log  function(s) are defined by an onset time followed by an charateristic time in integer days.\n",
    "##   Multiple exp and log functions can be overlaied on top of each other, achieved via e.g.:\n",
    "##   20110311,60,120          - two functions sharing the same onset time OR\n",
    "##   20110311,60;20170908,120 - separated by \";\"\n",
    "mintpy.timeFunc.polynomial = auto   #[int >= 0], auto for 1, degree of the polynomial function\n",
    "mintpy.timeFunc.periodic   = auto   #[1,0.5 / list_of_float / no], auto for no, periods in decimal years\n",
    "mintpy.timeFunc.stepDate   = auto   #[20110311,20170908 / 20120928T1733 / no], auto for no, step function(s)\n",
    "mintpy.timeFunc.exp        = auto   #[20110311,60 / 20110311,60,120 / 20110311,60;20170908,120 / no], auto for no\n",
    "mintpy.timeFunc.log        = auto   #[20110311,60 / 20110311,60,120 / 20110311,60;20170908,120 / no], auto for no\n",
    "\n",
    "## Uncertainty quantification methods:\n",
    "## a. residue    - propagate from fitting residue assuming normal dist. in time (Fattahi & Amelung, 2015, JGR)\n",
    "## b. covariance - propagate from time series (co)variance matrix\n",
    "## c. bootstrap  - bootstrapping (independently resampling with replacement; Efron & Tibshirani, 1986, Stat. Sci.)\n",
    "mintpy.timeFunc.uncertaintyQuantification = auto   #[residue, covariance, bootstrap], auto for residue\n",
    "mintpy.timeFunc.timeSeriesCovFile         = auto   #[filename / no], auto for no, time series covariance file\n",
    "mintpy.timeFunc.bootstrapCount            = auto   #[int>1], auto for 400, number of iterations for bootstrapping\n",
    "\n",
    "\n",
    "########## 11.1 geocode (post-processing)\n",
    "# for input dataset in radar coordinates only\n",
    "# commonly used resolution in meters and in degrees (on equator)\n",
    "# 100,         90,          60,          50,          40,          30,          20,          10\n",
    "# 0.000925926, 0.000833334, 0.000555556, 0.000462963, 0.000370370, 0.000277778, 0.000185185, 0.000092593\n",
    "mintpy.geocode              = auto  #[yes / no], auto for yes\n",
    "mintpy.geocode.SNWE         = auto  #[-1.2,0.5,-92,-91 / none ], auto for none, output extent in degree\n",
    "mintpy.geocode.laloStep     = auto  #[-0.000555556,0.000555556 / None], auto for None, output resolution in degree\n",
    "mintpy.geocode.interpMethod = auto  #[nearest], auto for nearest, interpolation method\n",
    "mintpy.geocode.fillValue    = auto  #[np.nan, 0, ...], auto for np.nan, fill value for outliers.\n",
    "\n",
    "########## 11.2 google_earth (post-processing)\n",
    "mintpy.save.kmz             = auto   #[yes / no], auto for yes, save geocoded velocity to Google Earth KMZ file\n",
    "\n",
    "########## 11.3 hdfeos5 (post-processing)\n",
    "mintpy.save.hdfEos5         = auto   #[yes / no], auto for no, save time-series to HDF-EOS5 format\n",
    "mintpy.save.hdfEos5.update  = auto   #[yes / no], auto for no, put XXXXXXXX as endDate in output filename\n",
    "mintpy.save.hdfEos5.subset  = auto   #[yes / no], auto for no, put subset range info   in output filename\n",
    "\n",
    "########## 11.4 plot\n",
    "# for high-resolution plotting, increase mintpy.plot.maxMemory\n",
    "# for fast plotting with more parallelization, decrease mintpy.plot.maxMemory\n",
    "mintpy.plot           = auto  #[yes / no], auto for yes, plot files generated by default processing to pic folder\n",
    "mintpy.plot.dpi       = auto  #[int], auto for 150, number of dots per inch (DPI)\n",
    "mintpy.plot.maxMemory = auto  #[float], auto for 4, max memory used by one call of view.py for plotting.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
